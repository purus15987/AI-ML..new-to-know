{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Models"
      ],
      "metadata": {
        "id": "Sfs1_oe0ZJez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diffusion models are a class of `generative models` that create high-quality images, videos, and even text by gradually refining noise into structured data. They are currently the state-of-the-art in generative AI, o`utperforming GANs and VAEs` in many tasks.\n",
        "\n",
        "These models have been used in Stable Diffusion, DALL·E 2, Imagen, and Gen-2, enabling text-to-image, video synthesis, and music generation."
      ],
      "metadata": {
        "id": "qdWW6BHJZREu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ Noise Scheduler (Forward Diffusion Process)\n",
        "def forward_diffusion(x, t, noise):\n",
        "    \"\"\"Adds noise to an image at time step t.\"\"\"\n",
        "    alpha_t = torch.exp(-0.02 * t)  # Noise schedule\n",
        "    noisy_x = alpha_t * x + (1 - alpha_t) * noise\n",
        "    return noisy_x\n",
        "\n",
        "# 2️⃣ Simple U-Net Architecture for Denoising\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, 3, padding=1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# 3️⃣ Training Loop\n",
        "def train_diffusion_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SimpleUNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Load MNIST Dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(10):\n",
        "        for images, _ in train_loader:\n",
        "            images = images.to(device)\n",
        "            noise = torch.randn_like(images).to(device)\n",
        "            t = torch.randint(0, 100, (images.shape[0],), device=device) / 100  # Random timestep\n",
        "            noisy_images = forward_diffusion(images, t[:, None, None, None], noise)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predicted_denoised = model(noisy_images)\n",
        "            loss = criterion(predicted_denoised, images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "    return model\n",
        "\n",
        "# 4️⃣ Generating Images\n",
        "def generate_images(model, num_images=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn((num_images, 1, 28, 28)).to(device)\n",
        "        generated_images = model(noise).cpu()\n",
        "\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(10, 2))\n",
        "    for i in range(num_images):\n",
        "        axs[i].imshow(generated_images[i].squeeze(), cmap='gray')\n",
        "        axs[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Train and Generate!\n",
        "model = train_diffusion_model()\n",
        "generate_images(model)"
      ],
      "metadata": {
        "id": "y0ix5yd3N3vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIgTQcH0YwCz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Hyperparameters\n",
        "T = 1000  # Number of timesteps\n",
        "BETA_START = 1e-4\n",
        "BETA_END = 0.02\n",
        "DATA_DIM = 1  # 1D data for simplicity\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 100\n",
        "\n",
        "# Variance schedule (linear)\n",
        "betas = torch.linspace(BETA_START, BETA_END, T)\n",
        "alphas = 1.0 - betas\n",
        "alpha_bars = torch.cumprod(alphas, dim=0)  # \\bar{\\alpha}_t = \\prod_{s=1}^t (1 - \\beta_s)\n",
        "\n",
        "# Forward process: q(x_t | x_0)\n",
        "def forward_process(x_0, t, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    x_0: Original data [batch_size, data_dim]\n",
        "    t: Timestep [batch_size]\n",
        "    Returns: x_t = sqrt(\\bar{\\alpha}_t) * x_0 + sqrt(1 - \\bar{\\alpha}_t) * \\epsilon\n",
        "    \"\"\"\n",
        "    alpha_bar_t = alpha_bars[t].to(device)  # [batch_size]\n",
        "    noise = torch.randn_like(x_0).to(device)  # \\epsilon ~ N(0, I)\n",
        "    x_t = (alpha_bar_t.sqrt() * x_0) + ((1 - alpha_bar_t).sqrt() * noise)\n",
        "    return x_t, noise\n",
        "\n",
        "# Simple neural network to predict noise \\epsilon_\\theta(x_t, t)\n",
        "class NoisePredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super(NoisePredictor, self).__init__()\n",
        "        self.time_embedding = nn.Embedding(T, hidden_dim)  # Embed timestep t\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim + hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_t, t):\n",
        "        t_embed = self.time_embedding(t)  # [batch_size, hidden_dim]\n",
        "        x_input = torch.cat([x_t, t_embed], dim=-1)  # Concatenate x_t and t_embed\n",
        "        return self.net(x_input)\n",
        "\n",
        "# Reverse process sampling: p_\\theta(x_{t-1} | x_t)\n",
        "def reverse_process(model, x_t, t, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    x_t: Noisy data at timestep t\n",
        "    t: Current timestep (scalar or [batch_size])\n",
        "    Returns: x_{t-1} = (1/sqrt(\\alpha_t)) * (x_t - (\\beta_t/sqrt(1-\\bar{\\alpha}_t)) * \\epsilon_\\theta) + \\sigma_t * z\n",
        "    \"\"\"\n",
        "    beta_t = betas[t].to(device)\n",
        "    alpha_t = alphas[t].to(device)\n",
        "    alpha_bar_t = alpha_bars[t].to(device)\n",
        "\n",
        "    # Predict noise with the model\n",
        "    epsilon_theta = model(x_t, t)\n",
        "\n",
        "    # Compute mean of p_\\theta(x_{t-1} | x_t)\n",
        "    mu_theta = (1 / alpha_t.sqrt()) * (x_t - (beta_t / (1 - alpha_bar_t).sqrt()) * epsilon_theta)\n",
        "\n",
        "    # Variance (simplified as \\beta_t in DDPM)\n",
        "    sigma_t = beta_t.sqrt()\n",
        "    z = torch.randn_like(x_t).to(device) if t > 0 else 0  # No noise at t=0\n",
        "    x_t_minus_1 = mu_theta + sigma_t * z\n",
        "    return x_t_minus_1\n",
        "\n",
        "# Generate toy dataset (e.g., samples from a mixture of Gaussians)\n",
        "def generate_data(n_samples=1000):\n",
        "    data = torch.cat([\n",
        "        torch.randn(n_samples // 2, DATA_DIM) * 0.1 - 1.0,  # Mean -1\n",
        "        torch.randn(n_samples // 2, DATA_DIM) * 0.1 + 1.0   # Mean +1\n",
        "    ])\n",
        "    return data\n",
        "\n",
        "# Training loop\n",
        "def train_diffusion_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = NoisePredictor(input_dim=DATA_DIM).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    data = generate_data(BATCH_SIZE * 10).to(device)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for _ in range(10):  # Mini-batches\n",
        "            # Sample random batch and timesteps\n",
        "            batch = data[torch.randperm(data.size(0))[:BATCH_SIZE]]\n",
        "            t = torch.randint(0, T, (BATCH_SIZE,), device=device)\n",
        "\n",
        "            # Forward process\n",
        "            x_t, true_noise = forward_process(batch, t, device)\n",
        "\n",
        "            # Predict noise\n",
        "            pred_noise = model(x_t, t)\n",
        "\n",
        "            # Loss: MSE between predicted and true noise\n",
        "            loss = F.mse_loss(pred_noise, true_noise)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss / 10:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Sampling function\n",
        "def sample_diffusion_model(model, n_samples=1000, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Start from pure noise\n",
        "        x_t = torch.randn(n_samples, DATA_DIM).to(device)\n",
        "\n",
        "        # Reverse process from T to 0\n",
        "        for t in reversed(range(T)):\n",
        "            t_tensor = torch.full((n_samples,), t, dtype=torch.long, device=device)\n",
        "            x_t = reverse_process(model, x_t, t_tensor, device)\n",
        "\n",
        "        return x_t\n",
        "\n",
        "# Run the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = train_diffusion_model()\n",
        "\n",
        "# Generate samples\n",
        "samples = sample_diffusion_model(model, n_samples=1000, device=device)\n",
        "\n",
        "# Plot original data vs. generated samples\n",
        "original_data = generate_data(1000).cpu().numpy()\n",
        "samples = samples.cpu().numpy()\n",
        "\n",
        "plt.hist(original_data, bins=50, alpha=0.5, label=\"Original Data\", density=True)\n",
        "plt.hist(samples, bins=50, alpha=0.5, label=\"Generated Samples\", density=True)\n",
        "plt.legend()\n",
        "plt.title(\"Diffusion Model: Original vs Generated Data\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparameters\n",
        "T = 1000  # Number of timesteps\n",
        "BETA_START = 1e-4\n",
        "BETA_END = 0.02\n",
        "IMG_SIZE = 28\n",
        "CHANNELS = 1  # MNIST is grayscale\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 20  # Increased epochs for images\n",
        "\n",
        "# Variance schedule (linear)\n",
        "betas = torch.linspace(BETA_START, BETA_END, T)\n",
        "alphas = 1.0 - betas\n",
        "alpha_bars = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "# Forward process: q(x_t | x_0)\n",
        "def forward_process(x_0, t, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    x_0: [batch_size, channels, height, width]\n",
        "    t: [batch_size]\n",
        "    Returns: x_t and noise\n",
        "    \"\"\"\n",
        "    alpha_bar_t = alpha_bars[t].to(device).view(-1, 1, 1, 1)  # Shape for broadcasting\n",
        "    noise = torch.randn_like(x_0).to(device)\n",
        "    x_t = (alpha_bar_t.sqrt() * x_0) + ((1 - alpha_bar_t).sqrt() * noise)\n",
        "    return x_t, noise\n",
        "\n",
        "# Simple U-Net for noise prediction\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self, time_dim=64):\n",
        "        super(SimpleUNet, self).__init__()\n",
        "        self.time_embedding = nn.Embedding(T, time_dim)\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Conv2d(CHANNELS, 32, 3, padding=1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 3, padding=1, stride=2)  # Downsample\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "        # Decoder\n",
        "        self.dec1 = nn.ConvTranspose2d(128, 64, 3, padding=1, stride=2, output_padding=1)  # Upsample\n",
        "        self.dec2 = nn.Conv2d(64 + 32, 32, 3, padding=1)  # Skip connection concatenation\n",
        "        self.dec3 = nn.Conv2d(32, CHANNELS, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Time embedding\n",
        "        t_embed = self.time_embedding(t).view(-1, 64, 1, 1)  # [batch_size, time_dim, 1, 1]\n",
        "\n",
        "        # Encoder\n",
        "        e1 = F.relu(self.enc1(x))           # [batch, 32, 28, 28]\n",
        "        e2 = F.relu(self.enc2(e1))          # [batch, 64, 14, 14]\n",
        "\n",
        "        # Bottleneck\n",
        "        b = F.relu(self.bottleneck(e2))     # [batch, 128, 14, 14]\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d1 = F.relu(self.dec1(b))           # [batch, 64, 28, 28]\n",
        "        d1 = torch.cat([d1, e1], dim=1)     # [batch, 96, 28, 28] (skip from e1)\n",
        "        d2 = F.relu(self.dec2(d1))          # [batch, 32, 28, 28]\n",
        "        out = self.dec3(d2)                 # [batch, 1, 28, 28]\n",
        "        return out\n",
        "\n",
        "# Reverse process sampling\n",
        "def reverse_process(model, x_t, t, device=\"cpu\"):\n",
        "    beta_t = betas[t].to(device).view(-1, 1, 1, 1)\n",
        "    alpha_t = alphas[t].to(device).view(-1, 1, 1, 1)\n",
        "    alpha_bar_t = alpha_bars[t].to(device).view(-1, 1, 1, 1)\n",
        "\n",
        "    epsilon_theta = model(x_t, t)\n",
        "    mu_theta = (1 / alpha_t.sqrt()) * (x_t - (beta_t / (1 - alpha_bar_t).sqrt()) * epsilon_theta)\n",
        "    sigma_t = beta_t.sqrt()\n",
        "    z = torch.randn_like(x_t).to(device) if t.max() > 0 else 0  # No noise at t=0\n",
        "    x_t_minus_1 = mu_theta + sigma_t * z\n",
        "    return x_t_minus_1\n",
        "\n",
        "# Training loop\n",
        "def train_diffusion_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SimpleUNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Load MNIST\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_idx, (images, _) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            t = torch.randint(0, T, (images.size(0),), device=device)\n",
        "\n",
        "            # Forward process\n",
        "            x_t, true_noise = forward_process(images, t, device)\n",
        "\n",
        "            # Predict noise\n",
        "            pred_noise = model(x_t, t)\n",
        "\n",
        "            # Loss\n",
        "            loss = F.mse_loss(pred_noise, true_noise)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Avg Loss: {avg_loss:.4f}\")\n",
        "    return model\n",
        "\n",
        "# Sampling function\n",
        "def sample_diffusion_model(model, n_samples=5, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Start from pure noise\n",
        "        x_t = torch.randn(n_samples, CHANNELS, IMG_SIZE, IMG_SIZE).to(device)\n",
        "\n",
        "        # Reverse process\n",
        "        for t in reversed(range(T)):\n",
        "            t_tensor = torch.full((n_samples,), t, dtype=torch.long, device=device)\n",
        "            x_t = reverse_process(model, x_t, t_tensor, device)\n",
        "\n",
        "        return x_t\n",
        "\n",
        "# Train and generate\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = train_diffusion_model()\n",
        "\n",
        "# Generate samples\n",
        "samples = sample_diffusion_model(model, n_samples=5, device=device)\n",
        "samples = samples.cpu()\n",
        "\n",
        "# Plot generated images\n",
        "fig, axs = plt.subplots(1, 5, figsize=(10, 2))\n",
        "for i in range(5):\n",
        "    axs[i].imshow(samples[i].squeeze(), cmap='gray')\n",
        "    axs[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8IcMsErwOByq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine variance schedule\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    \"\"\"\n",
        "    Returns betas based on a cosine schedule.\n",
        "    s: Small shift to prevent extreme values.\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    t = torch.linspace(0, timesteps, steps, dtype=torch.float32) / timesteps\n",
        "    f_t = torch.cos(((t + s) / (1 + s)) * (np.pi / 2)) ** 2\n",
        "    alpha_bars = f_t / f_t[0]  # Normalize so alpha_bar_0 = 1\n",
        "    betas = 1 - alpha_bars[1:] / alpha_bars[:-1]  # beta_t = 1 - alpha_t\n",
        "    betas = torch.clamp(betas, 0, 0.999)  # Ensure betas stay in (0, 1)\n",
        "    return betas\n",
        "\n",
        "# Precompute schedule\n",
        "betas = cosine_beta_schedule(T)"
      ],
      "metadata": {
        "id": "Jnea-NhrOGmA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}